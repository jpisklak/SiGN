<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Information-Theoretic Statistics • SiGN</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="96x96" href="../favicon-96x96.png">
<link rel="icon" type="”image/svg+xml”" href="../favicon.svg">
<link rel="apple-touch-icon" sizes="180x180" href="../apple-touch-icon.png">
<link rel="icon" sizes="any" href="../favicon.ico">
<link rel="manifest" href="../site.webmanifest">
<!-- mathjax math --><script src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script><script>
  window.MathJax = {
    chtml: {
      fontURL: "https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/output/chtml/fonts/woff-v2"
    }
  };
</script><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Information-Theoretic Statistics">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">SiGN</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.0.0.9000</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../articles/SiGN.html">Get started</a></li>
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles">
<li><hr class="dropdown-divider"></li>
    <li><h6 class="dropdown-header" data-toc-skip>Basics</h6></li>
    <li><a class="dropdown-item" href="../articles/squires_fantino.html">Classic Concurrent-Chains</a></li>
    <li><a class="dropdown-item" href="../articles/batch-predict.html">Predictions From Data Frames</a></li>
    <li><hr class="dropdown-divider"></li>
    <li><h6 class="dropdown-header" data-toc-skip>Model Evaluation</h6></li>
    <li><a class="dropdown-item" href="../articles/eval_descriptive.html">Descriptive Statistics</a></li>
    <li><a class="dropdown-item" href="../articles/eval_info-theoretic.html">Information-Theoretic Statistics</a></li>
  </ul>
</li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">Changelog</a></li>
<li class="nav-item"><a class="external-link nav-link" href="https://jpisklak.shinyapps.io/SiGN_Calc/">Online Calculator</a></li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/SiGN-R/SiGN/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">



<script src="eval_info-theoretic_files/kePrint-0.0.1/kePrint.js"></script><link href="eval_info-theoretic_files/lightable-0.0.1/lightable.css" rel="stylesheet">
<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.svg" class="logo" alt=""><h1>Information-Theoretic Statistics</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/SiGN-R/SiGN/blob/master/vignettes/eval_info-theoretic.Rmd" class="external-link"><code>vignettes/eval_info-theoretic.Rmd</code></a></small>
      <div class="d-none name"><code>eval_info-theoretic.Rmd</code></div>
    </div>

    
    
<p>In many scientific contexts, it is not enough to assess how well a
model fits the data; we also need to compare competing models and
determine which offers the most parsimonious and explanatory account of
the observed behaviour. Descriptive metrics such as RMSE or <span class="math inline">\(R^2\)</span> can provide insight into absolute fit
but do not account for model complexity—and are not grounded in
likelihood theory.</p>
<p>This vignette introduces a set of information-theoretic model
comparison tools for available via the <code>$info_criteria</code>
output of the <code><a href="../reference/choice_mod_eval.html">choice_mod_eval()</a></code> function. These
include:</p>
<ul>
<li><p><strong>Log-likelihoods</strong>, which quantify how well a model
predicts observed outcomes under a specified error
distribution;</p></li>
<li><p><strong>Akaike Information Criterion (AIC)</strong> and
<strong>Bayesian Information Criterion (BIC)</strong>, which extend the
likelihood framework by penalising for model complexity.</p></li>
</ul>
<p>The calculations are based on a beta-distributed error model, which
is well suited to evaluating predictions of choice
proportions—particularly when those proportions are bounded between 0
and 1 and exhibit non-constant variance.</p>
<p>This vignette outlines the rationale behind these metrics, describes
the underlying error model assumptions, and demonstrates how to compute
and interpret the information-theoretic outputs.</p>
<div class="section level2">
<h2 id="general-usage">General Usage<a class="anchor" aria-label="anchor" href="#general-usage"></a>
</h2>
<p>To compute information-theoretic model evaluation metrics using
<code><a href="../reference/choice_mod_eval.html">choice_mod_eval()</a></code>, three inputs are required:</p>
<ul>
<li><p>A vector of <code>observed</code> choice proportions;</p></li>
<li><p>A vector of <code>predicted</code> choice proportions from the
model;</p></li>
<li><p>An integer <code>k</code> indicating the number of free
parameters used by the model that generated the predictions.</p></li>
</ul>
<p>An optional <code>epsilon</code> value may also be specified to bound
the predictions away from 0 and 1; this is discussed in more detail
later.</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/choice_mod_eval.html">choice_mod_eval</a></span><span class="op">(</span><span class="va">observed</span>, <span class="va">predicted</span>, k <span class="op">=</span> <span class="fl">0</span>, epsilon <span class="op">=</span> <span class="fl">0.001</span>, <span class="va">...</span><span class="op">)</span></span></code></pre></div>
<p>When called, it returns a list containing three components:</p>
<ul>
<li><p><code>$desc_stats</code>: A data frame containing the descriptive
fit metrics described below (e.g., mean bias, RMSE, MAE, CCC, etc.).
These are discussed in detail in the companion article <a href="eval_descriptive.html">Model Evaluation: Descriptive
Statistics</a>.</p></li>
<li><p><code>$info_criteria</code>: A data frame containing
information-theoretic model comparison metrics (e.g., log-likelihood,
AIC, BIC) based on a beta-distributed error model.</p></li>
<li><p><code>$residuals</code>: A vector of residuals (i.e., observed
minus predicted values), provided for convenience in case users wish to
conduct additional analyses or visualizations.</p></li>
</ul>
<p>To illustrate how these metrics can inform model comparison, we begin
by revisiting a real-world case study from Dunn et al. (2024).</p>
</div>
<div class="section level2">
<h2 id="reassessing-dunn-et-al--2024">Reassessing Dunn et al. (2024)<a class="anchor" aria-label="anchor" href="#reassessing-dunn-et-al--2024"></a>
</h2>
<div class="section level3">
<h3 id="background">Background<a class="anchor" aria-label="anchor" href="#background"></a>
</h3>
<p>As described in the companion article (<a href="eval_descriptive.html">Model Evaluation: Descriptive
Statistics</a>), Dunn et al. (2024) evaluated model performance using
<span class="math inline">\(R^2\)</span> values derived from linear
regressions of observed versus predicted choice proportions. Their
analysis was applied to the full SiGN model as well as two simplified
variants: one omitting the model’s <span class="math inline">\(\beta\)</span> term, and one excluding the bonus
delay reduction component.</p>
<p>In addition to reporting <span class="math inline">\(R^2\)</span>
values, the original analysis included Bayes Factors derived from
regression-based log-likelihoods. In this vignette, we use the SiGN R
package to demonstrate a more principled approach—grounded in likelihood
theory and model complexity penalties—to comparing these models using
information-theoretic tools.</p>
</div>
</div>
<div class="section level2">
<h2 id="generating-the-models-and-their-predictions">Generating the Models and Their Predictions<a class="anchor" aria-label="anchor" href="#generating-the-models-and-their-predictions"></a>
</h2>
<p>We begin by generating predictions from the three model variants
evaluated in Dunn et al. (2024):</p>
<ol style="list-style-type: decimal">
<li><p>The <strong>full SiGN model</strong>, which includes all
terms;</p></li>
<li><p>A <strong>no-β</strong> variant, in which the <span class="math inline">\(\beta\)</span> parameter is disabled (removing its
influence on weighting conditional vs. terminal reinforcement);</p></li>
<li><p>A <strong>no-bonus</strong> variant, in which the model omits the
bonus delay reduction component that defines suboptimal choice scenarios
in the SiGN framework.</p></li>
</ol>
<p>The <code>subopt_avian</code> data set included in the package
contains all the necessary parameters to compute model predictions. Each
row represents a different experimental condition, and columns 9–24
provide the required model inputs.</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/SiGN-R/SiGN" class="external-link">SiGN</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Construct model input list</span></span>
<span><span class="va">params</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/do.call.html" class="external-link">do.call</a></span><span class="op">(</span><span class="va">choice_params</span>, <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">as.list</a></span><span class="op">(</span><span class="va">subopt_avian</span><span class="op">[</span><span class="fl">9</span><span class="op">:</span><span class="fl">24</span><span class="op">]</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>We then compute predictions for each of the three model variants:</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Full model predictions</span></span>
<span><span class="va">full</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/SiGN.html">SiGN</a></span><span class="op">(</span><span class="va">params</span><span class="op">)</span><span class="op">$</span><span class="va">details</span></span>
<span></span>
<span><span class="co"># No beta model predictions</span></span>
<span><span class="va">params</span><span class="op">$</span><span class="va">beta_toggle</span> <span class="op">=</span> <span class="cn">FALSE</span></span>
<span><span class="va">no_beta</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/SiGN.html">SiGN</a></span><span class="op">(</span><span class="va">params</span><span class="op">)</span><span class="op">$</span><span class="va">details</span></span></code></pre></div>
<p>For the no-bonus model, the predictions are constructed manually by
excluding the delay reduction mechanism. This yields a model equivalent
to that proposed by Spetch &amp; Dunn (1987).</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># No bonus model (without bonus delay reduction term)</span></span>
<span><span class="va">no_bonus</span> <span class="op">&lt;-</span> <span class="op">(</span><span class="va">full</span><span class="op">$</span><span class="va">r_a</span> <span class="op">*</span> <span class="va">full</span><span class="op">$</span><span class="va">dr_avg_a</span><span class="op">)</span> <span class="op">/</span></span>
<span>  <span class="op">(</span><span class="op">(</span><span class="va">full</span><span class="op">$</span><span class="va">r_a</span> <span class="op">*</span> <span class="va">full</span><span class="op">$</span><span class="va">dr_avg_a</span><span class="op">)</span> <span class="op">+</span> <span class="op">(</span><span class="va">full</span><span class="op">$</span><span class="va">r_b</span> <span class="op">*</span> <span class="va">full</span><span class="op">$</span><span class="va">dr_avg_b</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Apply boundary conditions</span></span>
<span><span class="va">cond_1</span> <span class="op">&lt;-</span> <span class="va">full</span><span class="op">$</span><span class="va">dr_avg_a</span> <span class="op">&gt;</span> <span class="fl">0</span> <span class="op">&amp;</span> <span class="va">full</span><span class="op">$</span><span class="va">dr_avg_b</span> <span class="op">&lt;</span> <span class="fl">0</span></span>
<span><span class="va">cond_0</span> <span class="op">&lt;-</span> <span class="va">full</span><span class="op">$</span><span class="va">dr_avg_a</span> <span class="op">&lt;</span> <span class="fl">0</span> <span class="op">&amp;</span> <span class="va">full</span><span class="op">$</span><span class="va">dr_avg_b</span> <span class="op">&gt;</span> <span class="fl">0</span></span>
<span></span>
<span><span class="co"># Enforce deterministic outcomes for certain boundary cases</span></span>
<span><span class="va">no_bonus</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html" class="external-link">ifelse</a></span><span class="op">(</span><span class="va">cond_1</span> <span class="op">==</span> <span class="cn">TRUE</span>, <span class="fl">1</span>,</span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html" class="external-link">ifelse</a></span><span class="op">(</span><span class="va">cond_0</span> <span class="op">==</span> <span class="cn">TRUE</span>, <span class="fl">0</span>, <span class="va">no_bonus</span><span class="op">)</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>Finally, for convenience, we store the observed and predicted choice
proportions in a data frame named <code>preds</code>:</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Combine observed and predicted choice proportions into a data frame</span></span>
<span><span class="va">preds</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span></span>
<span>  cp_obs <span class="op">=</span> <span class="va">subopt_avian</span><span class="op">$</span><span class="va">cp</span>,</span>
<span>  full <span class="op">=</span> <span class="va">full</span><span class="op">$</span><span class="va">cp</span>,</span>
<span>  no_bonus <span class="op">=</span> <span class="va">no_bonus</span>,</span>
<span>  no_beta <span class="op">=</span> <span class="va">no_beta</span><span class="op">$</span><span class="va">cp</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>These predictions will serve as the input for evaluating model fit
using information-theoretic criteria in the sections that follow.</p>
</div>
<div class="section level2">
<h2 id="the-error-model">The Error Model<a class="anchor" aria-label="anchor" href="#the-error-model"></a>
</h2>
<p>The original SiGN model, as reported in Dunn et al. (2024), contains
no free parameters. As such, it lacks any internal mechanism for fitting
itself to data. To enable likelihood-based comparisons between the three
model variants, we must introduce a statistical assumption about the
distribution of errors—that is, how observed outcomes might deviate from
the model’s predictions.</p>
<p>In their original analysis, Dunn et al. used <span class="math inline">\(R^2\)</span> values derived from linear
regressions on observed versus predicted values as a descriptive measure
of fit. This approach implicitly assumes that residuals are normally
distributed and homoscedastic:</p>
<p><span class="math display">\[
\varepsilon_i = y_i - \hat{y_i} \sim \mathcal{N}(0, \sigma^2)
\]</span></p>
<p>It follows from this that the observed values are normally
distributed around the predicted values:</p>
<p><span class="math display">\[
y_i \sim \mathcal{N}(\hat{y}_i, \sigma^2)
\]</span></p>
<ul>
<li><p><span class="math inline">\(\varepsilon_i\)</span>:
residual</p></li>
<li><p><span class="math inline">\(y_i\)</span> = observed choice
proportion for row <span class="math inline">\(i\)</span> in
<code>subopt_avian</code>.</p></li>
<li><p><span class="math inline">\(\hat{y}_i\)</span> = model-predicted
choice proportion.</p></li>
<li><p><span class="math inline">\(\sigma^2\)</span> = an unknown error
variance estimated from the residuals.</p></li>
</ul>
<p>This assumption is widespread—not only in statistical analyses
generally, but also within the suboptimal choice literature, where
choice proportions are often analysed using <em>t</em>-tests and ANOVAs,
both of which rely on the assumption of normally distributed errors.
However, this can be problematic when the outcome variable is a
proportion bounded between 0 and 1. The normal distribution has infinite
support and assigns nonzero probability to impossible values (i.e.,
those below 0 or above 1), making it a poor match for bounded data like
choice proportions.</p>
<p>In addition, choice data often exhibit non-constant variance
(heteroscedasticity): predictions near 0 or 1 tend to have smaller
variability, while predictions around 0.5 allow for greater spread.
Normal models assume homoscedasticity (constant variance), which may not
hold here. This is especially true in the suboptimal choice paradigm,
where empirical proportions often take on extreme values—exactly 0 or
1—further straining the normality assumption.</p>
<p>A more natural alternative is the Beta distribution, which is defined
only on the interval (0, 1). It is also highly flexible: depending on
its parameters, it can take on uniform, bell-shaped, U-shaped, or skewed
forms.</p>
<p>The Beta distribution is typically parameterised with two shape
parameters, <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>:</p>
<p><span class="math display">\[
y_i \sim \text{Beta}(\alpha_i,\ \beta_i)
\]</span></p>
<p>This unfortunately introduces some potential for confusion, as the
SiGN model also includes a parameter called <span class="math inline">\(\beta\)</span>—but the two are unrelated.</p>
<p>For the error model, we will assume that each observed choice
proportion <span class="math inline">\(y_i\)</span> arises from a Beta
distribution centered around the SiGN model’s prediction (i.e., <span class="math inline">\(\mu_i = \hat{y}_i\)</span>), with constant
precision <span class="math inline">\(\phi\)</span>. Under this
assumption, the two shape parameters become:</p>
<p><span class="math display">\[
\alpha_i = \mu_i \cdot \phi, \quad \beta_i = (1 - \mu_i) \cdot \phi
\]</span></p>
<p>So the error model can be written more specifically as:</p>
<p><span class="math display">\[
y_i \sim \text{Beta}(\mu_i \cdot \phi,\ (1 - \mu_i) \cdot \phi)
\]</span></p>
<ul>
<li><p><span class="math inline">\(y_i\)</span>: observed choice
proportion.</p></li>
<li><p><span class="math inline">\(\mu_i\)</span>: SiGN
model’s-predicted choice proportion.</p></li>
<li><p><span class="math inline">\(\phi\)</span>: precision parameter
(shared across all data points).</p></li>
</ul>
<p>This formulation reframes error not as a residual, but as variability
around a prediction. Each observation is treated as a random draw from a
Beta distribution whose mean is the SiGN model’s prediction. The spread
of this distribution reflects uncertainty in fit: when <span class="math inline">\(\phi\)</span> is large, predictions are tightly
clustered around <span class="math inline">\(\mu_i\)</span>; when small,
the distribution is more diffuse.</p>
<div class="section level3">
<h3 id="visualising-beta-error-shapes">Visualising Beta Error Shapes<a class="anchor" aria-label="anchor" href="#visualising-beta-error-shapes"></a>
</h3>
<p>To illustrate how the shape of the Beta distribution changes with the
prediction <span class="math inline">\(\mu\)</span>, the plot below
shows simulated distributions for five representative choice proportion
values. When <span class="math inline">\(\mu = 0.1\)</span>, the
distribution is strongly positively skewed (a floor effect). At <span class="math inline">\(\mu = 0.5\)</span>, the distribution is symmetric.
Near <span class="math inline">\(\mu = 0.9\)</span>, the pattern
reverses, with increasing negative skew.</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://tidyverse.tidyverse.org" class="external-link">tidyverse</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Parameters</span></span>
<span><span class="va">mu</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.1</span>, <span class="fl">0.25</span>, <span class="fl">0.5</span>, <span class="fl">0.75</span>, <span class="fl">0.9</span><span class="op">)</span></span>
<span><span class="va">phi</span> <span class="op">&lt;-</span> <span class="fl">10</span> <span class="co"># arbitary value</span></span>
<span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">1e5</span></span>
<span></span>
<span><span class="co"># Simulate Beta samples</span></span>
<span><span class="va">err_vals</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span></span>
<span>  value <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/stats/Beta.html" class="external-link">rbeta</a></span><span class="op">(</span><span class="va">n</span>, <span class="va">mu</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span> <span class="op">*</span> <span class="va">phi</span>, <span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="va">mu</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span> <span class="op">*</span> <span class="va">phi</span><span class="op">)</span>,</span>
<span>    <span class="fu"><a href="https://rdrr.io/r/stats/Beta.html" class="external-link">rbeta</a></span><span class="op">(</span><span class="va">n</span>, <span class="va">mu</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span> <span class="op">*</span> <span class="va">phi</span>, <span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="va">mu</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span><span class="op">)</span> <span class="op">*</span> <span class="va">phi</span><span class="op">)</span>,</span>
<span>    <span class="fu"><a href="https://rdrr.io/r/stats/Beta.html" class="external-link">rbeta</a></span><span class="op">(</span><span class="va">n</span>, <span class="va">mu</span><span class="op">[</span><span class="fl">3</span><span class="op">]</span> <span class="op">*</span> <span class="va">phi</span>, <span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="va">mu</span><span class="op">[</span><span class="fl">3</span><span class="op">]</span><span class="op">)</span> <span class="op">*</span> <span class="va">phi</span><span class="op">)</span>,</span>
<span>    <span class="fu"><a href="https://rdrr.io/r/stats/Beta.html" class="external-link">rbeta</a></span><span class="op">(</span><span class="va">n</span>, <span class="va">mu</span><span class="op">[</span><span class="fl">4</span><span class="op">]</span> <span class="op">*</span> <span class="va">phi</span>, <span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="va">mu</span><span class="op">[</span><span class="fl">4</span><span class="op">]</span><span class="op">)</span> <span class="op">*</span> <span class="va">phi</span><span class="op">)</span>,</span>
<span>    <span class="fu"><a href="https://rdrr.io/r/stats/Beta.html" class="external-link">rbeta</a></span><span class="op">(</span><span class="va">n</span>, <span class="va">mu</span><span class="op">[</span><span class="fl">5</span><span class="op">]</span> <span class="op">*</span> <span class="va">phi</span>, <span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="va">mu</span><span class="op">[</span><span class="fl">5</span><span class="op">]</span><span class="op">)</span> <span class="op">*</span> <span class="va">phi</span><span class="op">)</span></span>
<span>  <span class="op">)</span>,</span>
<span>  mu <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="va">mu</span>, each <span class="op">=</span> <span class="va">n</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Plot</span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html" class="external-link">ggplot</a></span><span class="op">(</span><span class="va">err_vals</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">value</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_histogram.html" class="external-link">geom_histogram</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/facet_wrap.html" class="external-link">facet_wrap</a></span><span class="op">(</span><span class="op">~</span><span class="va">mu</span>,</span>
<span>    nrow <span class="op">=</span> <span class="fl">1</span>,</span>
<span>    labeller <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/label_bquote.html" class="external-link">label_bquote</a></span><span class="op">(</span><span class="va">mu</span> <span class="op">==</span> <span class="fu">.</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/character.html" class="external-link">as.character</a></span><span class="op">(</span><span class="va">mu</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html" class="external-link">labs</a></span><span class="op">(</span></span>
<span>    title <span class="op">=</span> <span class="st">"Illustrating the Flexibility of the Beta Distribution"</span>,</span>
<span>    x <span class="op">=</span> <span class="st">"Simulated Choice Proportion"</span>,</span>
<span>    y <span class="op">=</span> <span class="st">"Count"</span></span>
<span>  <span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html" class="external-link">theme_bw</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/theme.html" class="external-link">theme</a></span><span class="op">(</span>panel.spacing.x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/grid/unit.html" class="external-link">unit</a></span><span class="op">(</span><span class="fl">1.125</span>, <span class="st">"lines"</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p><img src="eval_info-theoretic_files/figure-html/unnamed-chunk-6-1.png" width="100%" style="display: block; margin: auto;"></p>
<p>This behaviour underscores the strength of the Beta distribution as
an error model: it respects the bounds of proportion data, accommodates
skew, and adapts to mean-dependent variance. In contrast, the normal
model assumes symmetric, unbounded, and homoscedastic errors—assumptions
often violated in behavioural data.</p>
</div>
<div class="section level3">
<h3 id="how-variance-changes-with-the-mean">How Variance Changes with the Mean<a class="anchor" aria-label="anchor" href="#how-variance-changes-with-the-mean"></a>
</h3>
<p>The Beta distribution also exhibits a characteristic pattern where
variance decreases near the boundaries (0 or 1) and peaks at the
midpoint (<span class="math inline">\(\mu = 0.5\)</span>). This is
because the variance of a Beta distribution depends on both the mean
<span class="math inline">\(\mu\)</span> and precision <span class="math inline">\(\phi\)</span>. This mean-dependent variance helps
explain why the Beta model is well suited for choice data: it captures
the intuition that variability is greatest when choice is uncertain
(near 0.5) and smallest when choice is near-deterministic (near 0 or
1).</p>
<p>From Soch, et al. (2024), the variance of a beta distribution is:</p>
<p><span class="math display">\[
\text{Var}(X) = \frac{\alpha\beta}{(\alpha + \beta + 1) \cdot (\alpha +
\beta)^2}
\]</span></p>
<p>The following plot shows how the variance changes as a function of
<span class="math inline">\(\mu\)</span>, assuming a constant <span class="math inline">\(\phi = 10\)</span>:</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Parameters</span></span>
<span><span class="va">mu</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html" class="external-link">seq</a></span><span class="op">(</span><span class="fl">0.001</span>, <span class="fl">0.999</span>, by <span class="op">=</span> <span class="fl">0.001</span><span class="op">)</span></span>
<span><span class="va">phi</span> <span class="op">&lt;-</span> <span class="fl">10</span> <span class="co"># arbitrary value</span></span>
<span><span class="va">a</span> <span class="op">&lt;-</span> <span class="va">mu</span> <span class="op">*</span> <span class="va">phi</span></span>
<span><span class="va">b</span> <span class="op">&lt;-</span> <span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="va">mu</span><span class="op">)</span> <span class="op">*</span> <span class="va">phi</span></span>
<span><span class="va">v</span> <span class="op">&lt;-</span> <span class="op">(</span><span class="va">a</span> <span class="op">*</span> <span class="va">b</span><span class="op">)</span> <span class="op">/</span> <span class="op">(</span><span class="op">(</span><span class="va">a</span> <span class="op">+</span> <span class="va">b</span> <span class="op">+</span> <span class="fl">1</span><span class="op">)</span> <span class="op">*</span> <span class="op">(</span><span class="va">a</span> <span class="op">+</span> <span class="va">b</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html" class="external-link">ggplot</a></span><span class="op">(</span>mapping <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">mu</span>, y <span class="op">=</span> <span class="va">v</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html" class="external-link">geom_line</a></span><span class="op">(</span>linewidth <span class="op">=</span> <span class="fl">1</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html" class="external-link">labs</a></span><span class="op">(</span></span>
<span>    title <span class="op">=</span> <span class="st">"Beta Distribution Variance vs. Mean\n(with Φ = 10)"</span>,</span>
<span>    x <span class="op">=</span> <span class="st">"μ"</span>,</span>
<span>    y <span class="op">=</span> <span class="st">"Variance"</span></span>
<span>  <span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html" class="external-link">theme_bw</a></span><span class="op">(</span>base_size <span class="op">=</span> <span class="fl">14</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/theme.html" class="external-link">theme</a></span><span class="op">(</span>plot.title <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/element.html" class="external-link">element_text</a></span><span class="op">(</span>size <span class="op">=</span> <span class="fl">14</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p><img src="eval_info-theoretic_files/figure-html/unnamed-chunk-7-1.png" width="50%" style="display: block; margin: auto;"></p>
</div>
<div class="section level3">
<h3 id="estimating-a-value-for-phi">Estimating a Value for <span class="math inline">\(\phi\)</span><a class="anchor" aria-label="anchor" href="#estimating-a-value-for-phi"></a>
</h3>
<p>The Beta distribution used in our error model includes a precision
parameter, <span class="math inline">\(\phi\)</span>, which governs how
tightly the observed values are expected to cluster around the model’s
predictions. This plays a role analogous to variance (e.g., <span class="math inline">\(\sigma^2\)</span>) in Gaussian models—except that
here, larger values of <span class="math inline">\(\phi\)</span> imply
lower variability.</p>
<p>Rather than choosing <span class="math inline">\(\phi\)</span>
arbitrarily, we estimate it from the data using maximum likelihood
estimation. This approach finds the value of <span class="math inline">\(\phi\)</span> that makes the observed data most
probable under the assumed Beta error model.</p>
<p>In this context, the <strong>likelihood</strong> quantifies how well
the model—with a given value of <span class="math inline">\(\phi\)</span>—explains the observed choice
proportions. A higher likelihood means better alignment between model
and data. In practice, we minimise the negative log-likelihood, which
simplifies optimisation and improves numerical stability.</p>
<p>The <code>$phi</code> column returned by
<code><a href="../reference/choice_mod_eval.html">choice_mod_eval()</a></code> contains the estimated value of <span class="math inline">\(\phi\)</span> obtained via this method. Below, we
walk through a manual version of this calculation using the full SiGN
model.</p>
<div class="section level4">
<h4 id="estimating-phi-for-the-full-model-in-r">Estimating <span class="math inline">\(\phi\)</span> for the Full
Model in R<a class="anchor" aria-label="anchor" href="#estimating-phi-for-the-full-model-in-r"></a>
</h4>
<p>When estimating <span class="math inline">\(\phi\)</span>, a small
technical complication arises with the Beta distribution: specifically,
it is only defined for values strictly between 0 and 1. Because both the
observed and predicted choice proportions are allowed to include values
at the boundaries (e.g., 0 or 1), we need to apply a continuity
correction to ensure numerical stability. This adjustment is used only
for likelihood calculations—the original values are retained
elsewhere.</p>
<p>In the <code>subopt_avian</code> dataset, the observed proportions
often come close to 0 and 1 but do not actually reach them. However, the
SiGN model’s predictions do occasionally reach them. Thus, to
future-proof the code, we will apply the continuity correction to both
observed and predicted values.</p>
<p>The code below ensures that no observed or predicted value is smaller
than <code>epsilon = 0.001</code> or larger than
<code>1 - epsilon = 0.999</code>:</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">epsilon</span> <span class="op">&lt;-</span> <span class="fl">0.001</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">pmin</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">pmax</a></span><span class="op">(</span><span class="va">preds</span><span class="op">$</span><span class="va">cp_obs</span>, <span class="va">epsilon</span><span class="op">)</span>, <span class="fl">1</span> <span class="op">-</span> <span class="va">epsilon</span><span class="op">)</span></span>
<span><span class="va">mu</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">pmin</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">pmax</a></span><span class="op">(</span><span class="va">preds</span><span class="op">$</span><span class="va">full</span>, <span class="va">epsilon</span><span class="op">)</span>, <span class="fl">1</span> <span class="op">-</span> <span class="va">epsilon</span><span class="op">)</span></span></code></pre></div>
<ul>
<li><p><code>pmax(preds$cp_obs, epsilon)</code> replaces any values less
than 0.001 with 0.001</p></li>
<li><p><code>pmin(..., 1 - epsilon)</code> then caps any values above
0.999 at 0.999</p></li>
</ul>
<p>This correction is applied only for the purposes of likelihood
estimation. The unadjusted values are preserved for all other
computations and outputs.</p>
<p>It is worth noting that the choice of <code>epsilon</code> can
strongly influence the log-likelihood, especially when predicted or
observed values are near the boundaries (0 or 1). Users are encouraged
to check the sensitivity of the output to different epsilon values. That
said, for most applications involving behavioural data, a default of
<code>epsilon = 0.001</code> is likely to be both reasonable.</p>
<p>Next, we define the negative log-likelihood function for the Beta
distribution and use R’s <code><a href="https://rdrr.io/r/stats/optimize.html" class="external-link">optimize()</a></code> function to find the
value of <span class="math inline">\(\phi\)</span> that minimises
it:</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Define negative log-likelihood</span></span>
<span><span class="va">neg_loglik</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">phi</span>, <span class="va">y</span>, <span class="va">mu</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">alpha</span> <span class="op">&lt;-</span> <span class="va">mu</span> <span class="op">*</span> <span class="va">phi</span></span>
<span>  <span class="va">beta</span> <span class="op">&lt;-</span> <span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="va">mu</span><span class="op">)</span> <span class="op">*</span> <span class="va">phi</span></span>
<span>  <span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Beta.html" class="external-link">dbeta</a></span><span class="op">(</span><span class="va">y</span>, <span class="va">alpha</span>, <span class="va">beta</span>, log <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># Estimate phi using MLE</span></span>
<span><span class="va">optim_result</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/optimize.html" class="external-link">optimize</a></span><span class="op">(</span><span class="va">neg_loglik</span>, interval <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">200</span><span class="op">)</span>, y <span class="op">=</span> <span class="va">y</span>, mu <span class="op">=</span> <span class="va">mu</span><span class="op">)</span></span>
<span><span class="va">phi_est</span> <span class="op">&lt;-</span> <span class="va">optim_result</span><span class="op">$</span><span class="va">minimum</span></span>
<span><span class="va">phi_est</span></span>
<span><span class="co">#&gt; [1] 8.698582</span></span></code></pre></div>
<p>As mentioned earlier, this estimated <span class="math inline">\(\phi\)</span> quantifies the model’s precision
under the Beta error model—that is, how tightly the observed values
cluster around the predictions from the full SiGN model. A higher value
suggests that the observed choice proportions are tightly clustered
around the predicted values, while a lower value indicates greater
variability or model misfit.</p>
</div>
</div>
</div>
<div class="section level2">
<h2 id="computing-the-total-log-likelihood">Computing the Total Log-Likelihood<a class="anchor" aria-label="anchor" href="#computing-the-total-log-likelihood"></a>
</h2>
<p>Once we’ve estimated the optimal value of <span class="math inline">\(\phi\)</span> we can compute the total
log-likelihood, which quantifies how well the model—given its
predictions and the fitted precision parameter—accounts for the observed
data.</p>
<p>Specifically, for each observed value <span class="math inline">\(y_i\)</span>, we evaluate the logarithm of the
Beta probability density function, using the model’s predicted mean
<span class="math inline">\(\mu_i\)</span> and shape parameters derived
from <span class="math inline">\(\phi\)</span>. Summing these values
across all observations yields the total log-likelihood:</p>
<p><span class="math display">\[
\log L = \sum \log[\text{Beta}(y_i | \alpha_i, \beta_i)]
\]</span></p>
<p>The <code>$logLik</code> column returned by
<code><a href="../reference/choice_mod_eval.html">choice_mod_eval()</a></code> reports this value automatically. Below,
we replicate the calculation manually for the full model, using the
corrected predictions (<code>mu</code>) and observed values
(<code>y</code>) from earlier:</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Function to compute total log-likelihood given mu, y, and phi</span></span>
<span><span class="va">compute_loglik</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">mu_raw</span>, <span class="va">y</span>, <span class="va">phi</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">alpha</span> <span class="op">&lt;-</span> <span class="va">mu</span> <span class="op">*</span> <span class="va">phi</span></span>
<span>  <span class="va">beta</span> <span class="op">&lt;-</span> <span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="va">mu</span><span class="op">)</span> <span class="op">*</span> <span class="va">phi</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Beta.html" class="external-link">dbeta</a></span><span class="op">(</span><span class="va">y</span>, <span class="va">alpha</span>, <span class="va">beta</span>, log <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="va">LL_full</span> <span class="op">&lt;-</span> <span class="fu">compute_loglik</span><span class="op">(</span><span class="va">preds</span><span class="op">$</span><span class="va">full</span>, <span class="va">y</span>, <span class="va">phi_est</span><span class="op">)</span></span>
<span><span class="va">LL_full</span></span>
<span><span class="co">#&gt; [1] -16.70615</span></span></code></pre></div>
<p>This total log-likelihood represents the joint plausibility of the
observed data under the full SiGN model with fitted <span class="math inline">\(\phi\)</span>. It is the foundational quantity
from which information-theoretic metrics like AIC and BIC are
derived.</p>
</div>
<div class="section level2">
<h2 id="comparing-the-models">Comparing the Models<a class="anchor" aria-label="anchor" href="#comparing-the-models"></a>
</h2>
<p>While log-likelihood values can be used to compare how well each
model accounts for the data, a more principled approach is to use the
Akaike Information Criterion (AIC) or Bayesian Information Criterion
(BIC). Both metrics are derived from the model’s total log-likelihood,
but they also include penalties for model complexity—discouraging
overfitting. BIC imposes a stronger penalty than AIC.</p>
<p>In this context, “model complexity” is measured by the number of free
parameters <span class="math inline">\(k\)</span>. The equations for AIC
and BIC are:</p>
<p><span class="math display">\[
\begin{aligned}
\text{AIC} &amp;= 2k - 2\log L \\
\text{BIC} &amp;= \log(n) \cdot k - 2\log L
\end{aligned}
\]</span></p>
<ul>
<li><p><span class="math inline">\(\log L\)</span> is the
log-likelihood.</p></li>
<li><p><span class="math inline">\(k\)</span> is the number of estimated
parameters (1 in this case).</p></li>
<li><p><span class="math inline">\(n\)</span> is the number of
observations.</p></li>
</ul>
<p>Although none of the three models include free parameters in their
predictive structure, the precision parameter <span class="math inline">\(\phi\)</span> in the Beta error model is estimated
from the data. This means that, for likelihood-based model comparison,
each model is effectively treated as having one free parameter.</p>
<p>Because <span class="math inline">\(k = 1\)</span> is the same for
all three models, the penalty terms <span class="math inline">\(2k\)</span> (AIC) and <span class="math inline">\(\log(n) \cdot k\)</span> (BIC) are constant across
models and do not affect their relative rankings. In such cases, model
selection based on AIC, BIC, or log-likelihood alone will lead to the
same conclusions.</p>
<div class="section level3">
<h3 id="extracting-likelihood-information">Extracting Likelihood Information<a class="anchor" aria-label="anchor" href="#extracting-likelihood-information"></a>
</h3>
<p>The code below applies the <code><a href="../reference/choice_mod_eval.html">choice_mod_eval()</a></code> function to
obtain log-likelihood, AIC, and BIC values for each model.</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">full</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/choice_mod_eval.html">choice_mod_eval</a></span><span class="op">(</span><span class="va">preds</span><span class="op">$</span><span class="va">cp_obs</span>, <span class="va">preds</span><span class="op">$</span><span class="va">full</span>, k <span class="op">=</span> <span class="fl">0</span><span class="op">)</span></span>
<span><span class="va">no_beta</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/choice_mod_eval.html">choice_mod_eval</a></span><span class="op">(</span><span class="va">preds</span><span class="op">$</span><span class="va">cp_obs</span>, <span class="va">preds</span><span class="op">$</span><span class="va">no_beta</span>, k <span class="op">=</span> <span class="fl">0</span><span class="op">)</span></span>
<span><span class="va">no_bonus</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/choice_mod_eval.html">choice_mod_eval</a></span><span class="op">(</span><span class="va">preds</span><span class="op">$</span><span class="va">cp_obs</span>, <span class="va">preds</span><span class="op">$</span><span class="va">no_bonus</span>, k <span class="op">=</span> <span class="fl">0</span><span class="op">)</span></span>
<span></span>
<span><span class="va">full</span><span class="op">$</span><span class="va">info_criteria</span>     <span class="co"># full model</span></span>
<span><span class="co">#&gt;   n_parameters      phi    logLik      AIC      BIC</span></span>
<span><span class="co">#&gt; 1            1 8.698582 -16.70615 35.41229 38.26432</span></span>
<span><span class="va">no_beta</span><span class="op">$</span><span class="va">info_criteria</span>  <span class="co"># no-beta model</span></span>
<span><span class="co">#&gt;   n_parameters      phi    logLik      AIC      BIC</span></span>
<span><span class="co">#&gt; 1            1 8.505385 -18.04257 38.08513 40.93716</span></span>
<span><span class="va">no_bonus</span><span class="op">$</span><span class="va">info_criteria</span> <span class="co"># no-bonus model</span></span>
<span><span class="co">#&gt;   n_parameters      phi    logLik      AIC      BIC</span></span>
<span><span class="co">#&gt; 1            1 2.387355 -212.1828 426.3657 429.2177</span></span></code></pre></div>
<p>Although we pass <code>k = 0</code> to the function, the
implementation automatically adds 1 internally to account for the
estimated precision parameter <span class="math inline">\(\phi\)</span>.
This design allows users to supply <code>k</code> as the number of
parameters in the predictive model itself, while keeping the error model
assumption consistent.</p>
<p><strong>Thus, users are not limited to evaluating the SiGN model—this
function can be applied to any model that produces predictions on the
(0, 1) interval, such as logistic regression, reinforcement learning
models, or other proportion-based models.</strong></p>
<blockquote>
<p>⚠️ Caveat: The predictive model should provide only the expected
value (i.e., mean structure), and not incorporate its own stochastic
error model. If the model already simulates or embeds variability (e.g.,
by sampling outcomes or including its own likelihood), then layering an
additional Beta error model on top may be inappropriate, as the
assumptions of <code><a href="../reference/choice_mod_eval.html">choice_mod_eval()</a></code> would no longer hold.</p>
</blockquote>
</div>
<div class="section level3">
<h3 id="bayes-factors">Bayes Factors<a class="anchor" aria-label="anchor" href="#bayes-factors"></a>
</h3>
<p>While log-likelihood, AIC, and BIC can each be used to compare how
well models account for the data, it is often helpful to convert these
metrics into a more interpretable scale. One such approach is the Bayes
Factor (BF), which expresses the relative evidence for one model over
another.</p>
<p>For instance:</p>
<ul>
<li><p>The model with the largest log-likelihood fits best.</p></li>
<li><p>The model with the smallest AIC or BIC is preferred.</p></li>
</ul>
<p>But the magnitude of these differences is difficult to interpret
directly. Bayes Factors solve this by transforming the difference in BIC
scores into a ratio of support:</p>
<p><span class="math display">\[
\text{BF}_{01} \approx \exp(\frac{1}{2}(\text{BIC}_1 - \text{BIC}_0))
\]</span> where:</p>
<ul>
<li>
<span class="math inline">\(\text{BIC}_0\)</span>: The BIC value for
the reduced version of the SiGN model (i.e., no bonus and no beta
versions).</li>
<li>
<span class="math inline">\(\text{BIC}_1\)</span>: The BIC value for
the full SiGN model.</li>
</ul>
<p>This formulation yields <span class="math inline">\(\text{BF}_{01}\)</span>, the evidence in favour of
the reduced model. Taking the reciprocal gives the “inverse Bayes
Factor” (<span class="math inline">\(\text{BF}_{10}\)</span>), which, in
this context, shows evidence in favour of the full model:</p>
<p><span class="math display">\[
\text{BF}_{10} = \frac{1}{\text{BF}_{01}}
\]</span></p>
<p>A <span class="math inline">\(BF_{10} &gt; 1\)</span> indicates
support for the full model, with larger values implying stronger
evidence.</p>
<p>The following table provides an interpretive scale for Bayes Factors,
based on Jeffreys (1961):</p>
<table class="table table table-bordered" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
Jeffreys (1961) Interpretation of the Inverse Bayes Factor (BF₁₀)
</caption>
<thead><tr>
<th style="text-align:left;">
Support for BF₁₀
</th>
<th style="text-align:left;">
Interpretation
</th>
</tr></thead>
<tbody>
<tr>
<td style="text-align:left;">
1-3
</td>
<td style="text-align:left;">
Anecdotal evidence
</td>
</tr>
<tr>
<td style="text-align:left;">
3-10
</td>
<td style="text-align:left;">
Substantial evidence
</td>
</tr>
<tr>
<td style="text-align:left;">
10-32
</td>
<td style="text-align:left;">
Strong evidence
</td>
</tr>
<tr>
<td style="text-align:left;">
32-100
</td>
<td style="text-align:left;">
Very strong evidence
</td>
</tr>
<tr>
<td style="text-align:left;">
&gt; 100
</td>
<td style="text-align:left;">
Decisive evidence
</td>
</tr>
</tbody>
</table>
<div class="section level4">
<h4 id="computing-bayes-factors-from-bic">Computing Bayes Factors from BIC<a class="anchor" aria-label="anchor" href="#computing-bayes-factors-from-bic"></a>
</h4>
<p>We start by storing the BIC values for each model for ease of
use:</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">bic_full</span> <span class="op">&lt;-</span> <span class="va">full</span><span class="op">$</span><span class="va">info_criteria</span><span class="op">$</span><span class="va">BIC</span></span>
<span><span class="va">bic_no_beta</span> <span class="op">&lt;-</span> <span class="va">no_beta</span><span class="op">$</span><span class="va">info_criteria</span><span class="op">$</span><span class="va">BIC</span></span>
<span><span class="va">bic_no_bonus</span> <span class="op">&lt;-</span> <span class="va">no_bonus</span><span class="op">$</span><span class="va">info_criteria</span><span class="op">$</span><span class="va">BIC</span></span></code></pre></div>
<div class="section level5">
<h5 id="comparison-full-model-vs--no-beta-model">Comparison: Full Model vs. No-<span class="math inline">\(\beta\)</span> Model<a class="anchor" aria-label="anchor" href="#comparison-full-model-vs--no-beta-model"></a>
</h5>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># BIC_1 = full, BIC_0 = no beta</span></span>
<span><span class="va">BF_01</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">exp</a></span><span class="op">(</span><span class="op">(</span><span class="va">bic_full</span> <span class="op">-</span> <span class="va">bic_no_beta</span><span class="op">)</span> <span class="op">/</span> <span class="fl">2</span><span class="op">)</span></span>
<span><span class="va">BF_10</span> <span class="op">&lt;-</span> <span class="fl">1</span> <span class="op">/</span> <span class="va">BF_01</span> <span class="co"># Evidence for full over no-beta</span></span>
<span><span class="va">BF_10</span></span>
<span><span class="co">#&gt; [1] 3.805395</span></span></code></pre></div>
<p>The inverse Bayes Factor (3.81) shows good positive evidence for the
inclusion of the SiGN model’s <span class="math inline">\(\beta\)</span>
term.</p>
</div>
<div class="section level5">
<h5 id="comparison-full-model-vs--no-bonus-model">Comparison: Full Model vs. No-Bonus Model<a class="anchor" aria-label="anchor" href="#comparison-full-model-vs--no-bonus-model"></a>
</h5>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># BIC_1 = full, BIC_0 = no bonus</span></span>
<span><span class="va">BF_01</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">exp</a></span><span class="op">(</span><span class="op">(</span><span class="va">bic_full</span> <span class="op">-</span> <span class="va">bic_no_bonus</span><span class="op">)</span> <span class="op">/</span> <span class="fl">2</span><span class="op">)</span></span>
<span><span class="va">BF_10</span> <span class="op">&lt;-</span> <span class="fl">1</span> <span class="op">/</span> <span class="va">BF_01</span> <span class="co"># Evidence for full over no bonus</span></span>
<span><span class="va">BF_10</span></span>
<span><span class="co">#&gt; [1] 7.84247e+84</span></span></code></pre></div>
<p>The inverse Bayes Factor (&gt; 100) shows decisive evidence for the
inclusion of bonus delay-reduction in the model.</p>
<p>At face value, a result like <code>7.84247e+84</code> may appear
absurdly large, but this is a mathematical property of Bayes Factors:
because they are computed by exponentiating half the difference in BIC,
even moderate BIC differences can yield very large values. Such results
are not errors—they simply reflect overwhelming support for one model
over the other on a log-probability scale.</p>
</div>
</div>
</div>
<div class="section level3">
<h3 id="conclusion">Conclusion<a class="anchor" aria-label="anchor" href="#conclusion"></a>
</h3>
<p>In both comparisons, the full SiGN model is preferred—especially over
the no-bonus variant, where the evidence is overwhelming. Although Dunn
et al. (2024) relied on a less appropriate analytical method—using
regressions of observed versus predicted values—their qualitative
conclusion was ultimately correct: the full model offers the best
account of the data.</p>
<p>That said, their method overstated the evidence for including the
<span class="math inline">\(\beta\)</span> term. The Bayes Factor
analysis presented here reveals a more modest but consistent advantage.
Still, as noted in the companion article (<a href="eval_descriptive.html">Model Evaluation: Descriptive
Statistics</a>), the role of <span class="math inline">\(\beta\)</span>
was never expected to produce dramatic shifts in the model’s
predictions. Its relatively subtle effect should not be taken as
evidence against its conceptual relevance.</p>
</div>
</div>
<div class="section level2">
<h2 id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<p>Dunn, R. M., Pisklak, J. M., McDevitt, M. A., &amp; Spetch, M. L.
(2024). Suboptimal choice: A review and quantification of the signal for
good news (SiGN) model. <em>Psychological Review</em>. <em>131</em>(1),
58-78. <a href="https://doi.org/10.1037/rev0000416" class="external-link uri">https://doi.org/10.1037/rev0000416</a></p>
<p>Jeffreys, H. (1948). <em>Theory of probability</em> (2nd Ed.).
Oxford</p>
<p>Soch, et al. (2024). The Book of Statistical Proofs (Version 2023).
<a href="https://doi.org/10.5281/ZENODO.4305949" class="external-link uri">https://doi.org/10.5281/ZENODO.4305949</a></p>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Jeffrey Pisklak, Roger Dunn, Margaret McDevitt, Marcia Spetch.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.3.</p>
</div>

    </footer>
</div>





  </body>
</html>
