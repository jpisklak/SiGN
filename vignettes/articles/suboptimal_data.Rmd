---
title: "Reproducing the Dunn et al. (2024) Analysis"
---

```{r, include = FALSE}
library(knitr)
opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

Dunn et al. (2024) compiled an exhaustive collection of studies examining *suboptimal choice*. This dataset is included in the SiGN package.

The complete, unfiltered data set is available via `subopt_full`. For model evaluation, however, Dunn et al. (2024) focused on a curated subset of studies involving pigeons and starlings—species that, particularly in the case of pigeons, were the most extensively studied and yielded the most robust and consistently replicated findings. This filtered data set is provided in the SiGN package as `subopt_avian`.

Each row in `subopt_avian` represents a distinct study condition. Many of its columns, specifically 9 through 24, directly correspond to parameters used by the `choice_params()` function (for specifics, consult the `subopt_avian` R documentation).

```{r}
library(SiGN)

# Column Names
names(subopt_avian)
```

One key column is `$cp`, which reflects the observed choice proportion reported by each study. These values can be directly compared to predictions from the SiGN model.

```{r}
# Model Predictions
#-------------------------------------------------------------------------------
# Extract relevant parameter columns (cols 9–24 align with choice_params())
data_cols <- subopt_avian[9:24]

# Construct model input list
params <- do.call(choice_params, as.list(data_cols))

# Generate model predictions
preds <- SiGN(params)$details
```

Before plotting the comparisons, it will be helpful to first compute some additional statistics to aid in model assessment:

1. An $R^2$ value to quantify the proportion of variance in the observed data accounted for by the SiGN model's predictions. 

2. The RMSE (root mean squared error) and MAE (mean absolute error), which both reflect the average discrepancy between predicted and observed values, with RMSE placing greater emphasis on larger errors.

```{r}
# Model Assessment
#-------------------------------------------------------------------------------
# Fit a linear model comparing observed vs predicted
reg <- lm(subopt_avian$cp ~ preds$cp)
r_sq <- summary(reg)$r.squared

# Root Mean Squared Error (RMSE)
rmse <- sqrt(mean((subopt_avian$cp - preds$cp)^2))

#Mean Absolute Error (MAE)
mae <- mean(abs(subopt_avian$cp - preds$cp))
```

The following plot illustrates the correspondence between observed and predicted choice proportions. The dashed line represents perfect prediction (y ~ x), while the solid line depicts the best-fitting linear regression.

```{r fig.width = 5, fig.height = 5, dpi = 300, fig.align = 'center', out.width = '80%'}
# Plot of Results
#-------------------------------------------------------------------------------
# Format regression equation and annotations
reg_eqn <- sprintf(
  "y = %.2f + %.2f x\n",
  reg$coefficients[1], reg$coefficients[2]
)
r_sq_text <- sprintf("R² = %.2f", r_sq)
rmse_text <- sprintf("RMSE = %.2f", rmse)
mae_text <- sprintf("MAE = %.2f", mae)

stats <- paste(r_sq_text, rmse_text, mae_text, sep = "\n")

# Draw Plot
plot(preds$cp, subopt_avian$cp,
  type = "n", las = 1,
  xlim = c(0, 1), ylim = c(0, 1),
  xlab = "Predicted",
  ylab = "Obtained"
)

# Reference line
abline(a = 0, b = 1, lwd = 1, lty = 3, col = "grey")

# Points
points(preds$cp, subopt_avian$cp, las = 1, cex = 1)

# Regression line
abline(a = reg$coefficients[1], b = reg$coefficients[2], lwd = 2)

# Annotation
text(x = 0.2, y = 0.85, labels = reg_eqn, cex = 0.85)
text(x = 0.2, y = 0.75, labels = stats, cex = 0.75)
```

The RMSE (`r round(rmse, 2)`) and MAE (`r round(mae, 2)`) indicate that the model's predictions deviate from the observed values by approximately 11 to 14 percentage points on average. This reflects a reasonably good fit to the `subopt_avian` data set and aligns with expectations, given the inherent variability across studies, species, and procedural differences.

## References

Dunn, R. M., Pisklak, J. M., McDevitt, M. A., & Spetch, M. L. (2024). Suboptimal choice: A review and quantification of the signal for good news (SiGN) model. *Psychological Review*. *131*(1), 58-78. https://doi.org/10.1037/rev0000416

